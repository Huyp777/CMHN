# CMHN

Cross-Modal Hashing for Efﬁciently Retrieving Moments in Videos
============================================================================
we propose an end-to-end Cross-Modal Hashing Network, dubbed CMHN, to efﬁciently retrieve target moments within the given video via various natural language queries. <br>
Speciﬁcally, it ﬁrst adopts a dual-path neural network to respectively learn the feature representations for video and query, and then it utilizes the cross-modal hashing strategy to guide the corresponding hash codes learning for them.<br>
Put simply, our proposed model jointly considers the discriminative feature learning and effective cross-modal hashing.<br> 
Moreover, we conduct extensive experiments on two public datasets ActivityNet Captions and TACoS. The experimental results show that our proposed model is more effective, efﬁcient and scalable than the state-of-the-art models.<br>
The introduction of CMHN in details will be given in the form of an authorized patent and a published paper within half a year.<br>
An illustration of the cross-modal moment retrieval and the framework of CMHN are shown in the following two figures.
![](https://github.com/Huyp777/MPLRForSub/raw/master/1.png)<br>
![](https://github.com/Huyp777/MPLRForSub/raw/master/2.png)
